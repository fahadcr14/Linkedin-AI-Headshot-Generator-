{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A83NFDuJWyda"
   },
   "outputs": [],
   "source": [
    "pip install -U peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fP_kRMLV5yw",
    "outputId": "8bbceca8-db67-44d4-d63e-07d74c5db690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.6/174.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.4/215.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\n",
      "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
      "tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.16.2 which is incompatible.\n",
      "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.23.4 which is incompatible.\n",
      "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U autotrain-advanced -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOm4atNaQCRl",
    "outputId": "2e42e7b5-0569-41f9-996c-73e6a18cbe72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.28.0-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.23.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (10.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
      "Installing collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.27.2\n",
      "    Uninstalling diffusers-0.27.2:\n",
      "      Successfully uninstalled diffusers-0.27.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autotrain-advanced 0.7.118 requires diffusers==0.27.2, but you have diffusers 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed diffusers-0.28.0\n",
      "Requirement already satisfied: invisible_watermark in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
      "Requirement already satisfied: Pillow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (10.3.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (1.25.2)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (4.8.0.76)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible_watermark) (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible_watermark) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->invisible_watermark) (12.5.40)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->invisible_watermark) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible_watermark) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers --upgrade\n",
    "!pip install invisible_watermark transformers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBpDTjsHIH7B",
    "outputId": "e748ccf5-ea0c-4835-af48-f246a390e1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: insightface in ./.venv/lib/python3.11/site-packages (0.7.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from insightface) (2.1.3)\n",
      "Requirement already satisfied: onnx in ./.venv/lib/python3.11/site-packages (from insightface) (1.17.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from insightface) (4.66.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from insightface) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (from insightface) (3.9.2)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from insightface) (11.0.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from insightface) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from insightface) (1.5.2)\n",
      "Requirement already satisfied: scikit-image in ./.venv/lib/python3.11/site-packages (from insightface) (0.24.0)\n",
      "Requirement already satisfied: easydict in ./.venv/lib/python3.11/site-packages (from insightface) (1.13)\n",
      "Requirement already satisfied: cython in ./.venv/lib/python3.11/site-packages (from insightface) (3.0.11)\n",
      "Requirement already satisfied: albumentations in ./.venv/lib/python3.11/site-packages (from insightface) (1.4.21)\n",
      "Requirement already satisfied: prettytable in ./.venv/lib/python3.11/site-packages (from insightface) (3.12.0)\n",
      "Requirement already satisfied: PyYAML in ./.venv/lib/python3.11/site-packages (from albumentations->insightface) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in ./.venv/lib/python3.11/site-packages (from albumentations->insightface) (2.9.2)\n",
      "Requirement already satisfied: albucore==0.0.20 in ./.venv/lib/python3.11/site-packages (from albumentations->insightface) (0.0.20)\n",
      "Requirement already satisfied: eval-type-backport in ./.venv/lib/python3.11/site-packages (from albumentations->insightface) (0.2.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in ./.venv/lib/python3.11/site-packages (from albumentations->insightface) (4.10.0.84)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in ./.venv/lib/python3.11/site-packages (from albucore==0.0.20->albumentations->insightface) (3.10.7)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in ./.venv/lib/python3.11/site-packages (from albucore==0.0.20->albumentations->insightface) (5.9.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->insightface) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib->insightface) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib->insightface) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->insightface) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib->insightface) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->insightface) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib->insightface) (2.9.0.post0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./.venv/lib/python3.11/site-packages (from onnx->insightface) (5.28.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.11/site-packages (from prettytable->insightface) (0.2.13)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->insightface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->insightface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->insightface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->insightface) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.8 in ./.venv/lib/python3.11/site-packages (from scikit-image->insightface) (3.4.2)\n",
      "Requirement already satisfied: imageio>=2.33 in ./.venv/lib/python3.11/site-packages (from scikit-image->insightface) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in ./.venv/lib/python3.11/site-packages (from scikit-image->insightface) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in ./.venv/lib/python3.11/site-packages (from scikit-image->insightface) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->insightface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->insightface) (3.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.0->albumentations->insightface) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.11/site-packages (from pydantic>=2.7.0->albumentations->insightface) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install insightface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gGo9-YwlGfW",
    "outputId": "dafd531a-c545-454c-a051-b9360487e780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: codeformer-pip in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
      "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (2.4.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (0.18.3)\n",
      "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (1.25.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (4.8.0.76)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (10.3.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (2.31.0)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (0.23.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (1.11.4)\n",
      "Requirement already satisfied: tb-nightly in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (2.17.0a20240602)\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (2.3.0+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (0.18.0+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (4.66.4)\n",
      "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (0.40.2)\n",
      "Requirement already satisfied: lpips in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (0.1.4)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from codeformer-pip) (5.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->codeformer-pip) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.1->codeformer-pip) (12.5.40)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->codeformer-pip) (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->codeformer-pip) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codeformer-pip) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codeformer-pip) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codeformer-pip) (2024.2.2)\n",
      "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->codeformer-pip) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->codeformer-pip) (2024.5.22)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->codeformer-pip) (24.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->codeformer-pip) (0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (1.64.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tb-nightly->codeformer-pip) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->codeformer-pip) (7.1.0)\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->codeformer-pip) (4.2.2)\n",
      "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->codeformer-pip) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->codeformer-pip) (3.18.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tb-nightly->codeformer-pip) (2.1.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->codeformer-pip) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->codeformer-pip) (1.7.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->codeformer-pip) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "pip install codeformer-pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "249wDei8VXiU"
   },
   "source": [
    "# **Necessary Importing Libararies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sXzSEa4NEzfM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#import insightface\n",
    "from insightface.app import FaceAnalysis # face detetction model\n",
    "from insightface.data import get_image # detect face\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lBblpcCF7wI",
    "outputId": "31c01e86-8331-43fb-cde6-744620d0850e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT9wyJreQLYz"
   },
   "source": [
    "# **Hugging Face Auth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "77b64e8b2be34a928e2dc5ba1f60f7cc",
      "b006b203843d4acd81b25a07fe68cdd7",
      "0281b324a6274151ac31a5674d819dbd",
      "4e2a60351fff40958844b1447694ea87",
      "678dcccf600f4de38909dc278a314f08",
      "671071d5a6a349ceb71a7ce7b21bd8eb",
      "364b8b9e53a041d8935bf465dfc5409d",
      "b5b97db8c112456e94b7e5e6293fba72",
      "4902855b497e494eb5e4c01b7eaab4a7",
      "3dc8ceb2df274f9b96eb6d300d847c3c",
      "09e1e67aeeaa4b8398952cb3e8b65581",
      "2c7f88fda52d4932bbbc606ce3f08527",
      "0db0276e66c34700ae0a99bb1e0e2369",
      "79f54caf4e5e4005bafebe2c948a24e1",
      "37dcee0369384427951611505f945117",
      "190f0fb5bdba44c3b9608ae1614b26b5",
      "16dca47caa2c43c5ac00549ee6c25268",
      "76630b08d8af4785a1330298fae95bfd",
      "ce9343a20c6740249ef5e347623c5337",
      "28987dec357e4337a4f601b629dce447",
      "f5230212187640a8b185d9275d5cfd05",
      "2885c7585372420bb5aec8819ca7454c",
      "d57171b035674a0599c3e6f50afa8f13",
      "07e4f197ebcd4822ab3e2a2b36655543",
      "b0126a7860f84df1a6dadee64983496d",
      "0a20bd56ad7f479e95d0d3e721669883",
      "fcb70b2f526c46d68955c0bc1bb5127f",
      "2531505b4b784db183365d99d526c361",
      "0f85ecca5d754781ad608963c64ef073",
      "ef8fce68730e4bbe8d74405c1603ac20",
      "5eea486b51b34cb799eded87857ba3ad",
      "4fb47c1b69894c12aa9a46345b07568a"
     ]
    },
    "id": "Yulpn3_7Rozx",
    "outputId": "68449803-63c0-49db-8e7d-14d352fe48dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b64e8b2be34a928e2dc5ba1f60f7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IldKwjo_NyKE"
   },
   "source": [
    "# **Text 2 image model loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "c372370604e445a78462be8c7ecdbf69",
      "c1c4f93d00ac4bde98b7c40b4d86498e",
      "0ec0aafdfa4448e39c271a255e6b5fff",
      "d827323911fe417ca0943bee5e644d48",
      "8d1656400bd54302b0867fb07fb93608",
      "b7ae04a34f3b4ad5a8a590be6d78c031",
      "6e664d77697d426987f9dd9392196e7b",
      "dc71a0e9b27c41168c56c2e75233ec2c",
      "f7c2024b8f1747f1909b3b73469c5fb8",
      "03af13bcd3e94bdd9446118abfce86c5",
      "d18ccd7599eb45ad940cd2bc5295c227"
     ]
    },
    "id": "168DMGYzQOym",
    "outputId": "777c284a-29ad-40a8-c56d-d7c1bc2d44f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c372370604e445a78462be8c7ecdbf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline, StableDiffusionXLImg2ImgPipeline\n",
    "import torch\n",
    "import peftv  \n",
    "\n",
    "prj_path = \"fahd9999/my-dreambooth-project\"\n",
    "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "     model,\n",
    "     torch_dtype=torch.float16,use_safetensors=True, variant=\"fp16\"\n",
    " )\n",
    "pipe.to(\"cuda\")\n",
    "pipe.load_lora_weights(prj_path, weight_name=\"pytorch_lora_weights.safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzeXKcdkEzfP"
   },
   "source": [
    "# ***Loading Face detection model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4jNdO1bEzfQ",
    "outputId": "c6077ae0-7850-4867-9588-dd119cfaf1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/faddy/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/faddy/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/faddy/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/faddy/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/faddy/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "[]\n",
      "Face detected: False\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Initialize the FaceAnalysis application\n",
    "app = FaceAnalysis(name='buffalo_l')\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "def check_face_in_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    faces = app.get(img)\n",
    "    print(faces)\n",
    "    # Set the flag based on whether a face is detected\n",
    "    face_detected_flag = len(faces) > 0\n",
    "    \n",
    "    return face_detected_flag\n",
    "\n",
    "# Example usage\n",
    "image_path = r'2.webp'\n",
    "is_face_detected = check_face_in_image(image_path)\n",
    "print(f\"Face detected: {is_face_detected}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QODaqlaREzfS"
   },
   "source": [
    "# ***Loading face swaping model***\n",
    "\n",
    "1.   Model is on my drive\n",
    "2.   Loading model using insight face and saving to face_swap_obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzPOrQ5DEzfS",
    "outputId": "77bda9e9-32f0-4ee0-d52d-b6a1a3e5b5d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "inswapper-shape: [1, 3, 128, 128]\n"
     ]
    }
   ],
   "source": [
    "face_swap_obj = insightface.model_zoo.get_model(r'/content/drive/My Drive/inswapper_128.onnx', download=False, download_zip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URlGR3XxWBXT"
   },
   "source": [
    "# **Face Swaping Main**\n",
    "\n",
    "*   Takes face_swapper(model)\n",
    "*   original_image is target image\n",
    "*   Source image is users face\n",
    "*   Source face and target face is extracted through face detection model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7rsqVWKREzfP"
   },
   "outputs": [],
   "source": [
    "def face_swaping(face_swapper,orginal_image,source_face,target_faces):\n",
    "\n",
    "    result_image = orginal_image.copy()\n",
    "    for i, face in enumerate(target_faces):\n",
    "        result_image = face_swapper.get(result_image, face, source_face, paste_back=True)\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KuE9oAEBEzfT"
   },
   "outputs": [],
   "source": [
    "def image_generation(source_image,target_image):\n",
    "  global face_swap_obj #inswapper model object\n",
    "  target_faces=app.get(img=target_image)\n",
    "  source_face=app.get(img=source_image)\n",
    "  source_face=source_face[0]\n",
    "  face_swapped_image=face_swaping(face_swap_obj,target_image,source_face,target_faces)\n",
    "  plt.imshow(face_swapped_image)\n",
    "  return face_swapped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oP9fILK83SS0"
   },
   "source": [
    "# **Image Enhancer Upscaler Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OT5smMCd3bsl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision.transforms.functional import normalize\n",
    "\n",
    "from codeformer.basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from codeformer.basicsr.utils import img2tensor, imwrite, tensor2img\n",
    "from codeformer.basicsr.utils.download_util import load_file_from_url\n",
    "from codeformer.basicsr.utils.realesrgan_utils import RealESRGANer\n",
    "from codeformer.basicsr.utils.registry import ARCH_REGISTRY\n",
    "from codeformer.facelib.utils.face_restoration_helper import FaceRestoreHelper\n",
    "from codeformer.facelib.utils.misc import is_gray\n",
    "\n",
    "pretrain_model_url = {\n",
    "    \"codeformer\": \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth\",\n",
    "    \"detection\": \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/detection_Resnet50_Final.pth\",\n",
    "    \"parsing\": \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/parsing_parsenet.pth\",\n",
    "    \"realesrgan\": \"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/RealESRGAN_x2plus.pth\",\n",
    "}\n",
    "\n",
    "# download weights\n",
    "if not os.path.exists(\"CodeFormer/weights/CodeFormer/codeformer.pth\"):\n",
    "    load_file_from_url(\n",
    "        url=pretrain_model_url[\"codeformer\"], model_dir=\"CodeFormer/weights/CodeFormer\", progress=True, file_name=None\n",
    "    )\n",
    "if not os.path.exists(\"CodeFormer/weights/facelib/detection_Resnet50_Final.pth\"):\n",
    "    load_file_from_url(\n",
    "        url=pretrain_model_url[\"detection\"], model_dir=\"CodeFormer/weights/facelib\", progress=True, file_name=None\n",
    "    )\n",
    "if not os.path.exists(\"CodeFormer/weights/facelib/parsing_parsenet.pth\"):\n",
    "    load_file_from_url(\n",
    "        url=pretrain_model_url[\"parsing\"], model_dir=\"CodeFormer/weights/facelib\", progress=True, file_name=None\n",
    "    )\n",
    "if not os.path.exists(\"CodeFormer/weights/realesrgan/RealESRGAN_x2plus.pth\"):\n",
    "    load_file_from_url(\n",
    "        url=pretrain_model_url[\"realesrgan\"], model_dir=\"CodeFormer/weights/realesrgan\", progress=True, file_name=None\n",
    "    )\n",
    "\n",
    "\n",
    "def imread(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "\n",
    "# set enhancer with RealESRGAN\n",
    "def set_realesrgan():\n",
    "    half = True if torch.cuda.is_available() else False\n",
    "    model = RRDBNet(\n",
    "        num_in_ch=3,\n",
    "        num_out_ch=3,\n",
    "        num_feat=64,\n",
    "        num_block=23,\n",
    "        num_grow_ch=32,\n",
    "        scale=2,\n",
    "    )\n",
    "    upsampler = RealESRGANer(\n",
    "        scale=2,\n",
    "        model_path=\"CodeFormer/weights/realesrgan/RealESRGAN_x2plus.pth\",\n",
    "        model=model,\n",
    "        tile=400,\n",
    "        tile_pad=40,\n",
    "        pre_pad=0,\n",
    "        half=half,\n",
    "    )\n",
    "    return upsampler\n",
    "\n",
    "\n",
    "upsampler = set_realesrgan()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "codeformer_net = ARCH_REGISTRY.get(\"CodeFormer\")(\n",
    "    dim_embd=512,\n",
    "    codebook_size=1024,\n",
    "    n_head=8,\n",
    "    n_layers=9,\n",
    "    connect_list=[\"32\", \"64\", \"128\", \"256\"],\n",
    ").to(device)\n",
    "ckpt_path = \"CodeFormer/weights/CodeFormer/codeformer.pth\"\n",
    "checkpoint = torch.load(ckpt_path)[\"params_ema\"]\n",
    "codeformer_net.load_state_dict(checkpoint)\n",
    "codeformer_net.eval()\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "\n",
    "def inference_app(image, background_enhance, face_upsample, upscale, codeformer_fidelity,file_name):\n",
    "    # take the default setting for the demo\n",
    "    has_aligned = False\n",
    "    only_center_face = False\n",
    "    draw_box = False\n",
    "    detection_model = \"retinaface_resnet50\"\n",
    "    print(\"Inp:\", image, background_enhance, face_upsample, upscale, codeformer_fidelity)\n",
    "\n",
    "    img = cv2.imread(str(image), cv2.IMREAD_COLOR)\n",
    "    print(\"\\timage size:\", img.shape)\n",
    "\n",
    "    upscale = int(upscale)  # convert type to int\n",
    "    if upscale > 4:  # avoid memory exceeded due to too large upscale\n",
    "        upscale = 4\n",
    "    if upscale > 2 and max(img.shape[:2]) > 1000:  # avoid memory exceeded due to too large img resolution\n",
    "        upscale = 2\n",
    "    if max(img.shape[:2]) > 1500:  # avoid memory exceeded due to too large img resolution\n",
    "        upscale = 1\n",
    "        background_enhance = False\n",
    "        face_upsample = False\n",
    "\n",
    "    face_helper = FaceRestoreHelper(\n",
    "        upscale,\n",
    "        face_size=512,\n",
    "        crop_ratio=(1, 1),\n",
    "        det_model=detection_model,\n",
    "        save_ext=\"png\",\n",
    "        use_parse=True,\n",
    "        device=device,\n",
    "    )\n",
    "    bg_upsampler = upsampler if background_enhance else None\n",
    "    face_upsampler = upsampler if face_upsample else None\n",
    "\n",
    "    if has_aligned:\n",
    "        # the input faces are already cropped and aligned\n",
    "        img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "        face_helper.is_gray = is_gray(img, threshold=5)\n",
    "        if face_helper.is_gray:\n",
    "            print(\"\\tgrayscale input: True\")\n",
    "        face_helper.cropped_faces = [img]\n",
    "    else:\n",
    "        face_helper.read_image(img)\n",
    "        # get face landmarks for each face\n",
    "        num_det_faces = face_helper.get_face_landmarks_5(\n",
    "            only_center_face=only_center_face, resize=640, eye_dist_threshold=5\n",
    "        )\n",
    "        print(f\"\\tdetect {num_det_faces} faces\")\n",
    "        # align and warp each face\n",
    "        face_helper.align_warp_face()\n",
    "\n",
    "    # face restoration for each cropped face\n",
    "    for idx, cropped_face in enumerate(face_helper.cropped_faces):\n",
    "        # prepare data\n",
    "        cropped_face_t = img2tensor(cropped_face / 255.0, bgr2rgb=True, float32=True)\n",
    "        normalize(cropped_face_t, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
    "        cropped_face_t = cropped_face_t.unsqueeze(0).to(device)\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                output = codeformer_net(cropped_face_t, w=codeformer_fidelity, adain=True)[0]\n",
    "                restored_face = tensor2img(output, rgb2bgr=True, min_max=(-1, 1))\n",
    "            del output\n",
    "            torch.cuda.empty_cache()\n",
    "        except RuntimeError as error:\n",
    "            print(f\"Failed inference for CodeFormer: {error}\")\n",
    "            restored_face = tensor2img(cropped_face_t, rgb2bgr=True, min_max=(-1, 1))\n",
    "\n",
    "        restored_face = restored_face.astype(\"uint8\")\n",
    "        face_helper.add_restored_face(restored_face)\n",
    "\n",
    "    # paste_back\n",
    "    if not has_aligned:\n",
    "        # upsample the background\n",
    "        if bg_upsampler is not None:\n",
    "            # Now only support RealESRGAN for upsampling background\n",
    "            bg_img = bg_upsampler.enhance(img, outscale=upscale)[0]\n",
    "        else:\n",
    "            bg_img = None\n",
    "        face_helper.get_inverse_affine(None)\n",
    "        # paste each restored face to the input image\n",
    "        if face_upsample and face_upsampler is not None:\n",
    "            restored_img = face_helper.paste_faces_to_input_image(\n",
    "                upsample_img=bg_img,\n",
    "                draw_box=draw_box,\n",
    "                face_upsampler=face_upsampler,\n",
    "            )\n",
    "        else:\n",
    "            restored_img = face_helper.paste_faces_to_input_image(upsample_img=bg_img, draw_box=draw_box)\n",
    "\n",
    "    # save restored img\n",
    "    save_path = f\"output/{file_name}.png\"\n",
    "    imwrite(restored_img, str(save_path))\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7y-JciyI3Vl9"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hR2cXandXsXt"
   },
   "source": [
    "# ***Text to image***\n",
    "> Takes prompt and generate image and save to img file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kxpdLZTnXuZP"
   },
   "outputs": [],
   "source": [
    "def generate_image_from_prompt_and_image(prompt, init_image):\n",
    "    # Convert the initial image to the appropriate format\n",
    "    if init_image:\n",
    "      #init_image = init_image.convert(\"RGB\")\n",
    "\n",
    "      # Generate an image using the pipeline with reduced inference steps and adjusted dimensions\n",
    "      #generated_image = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images[0]\n",
    "      generated_image = pipe(prompt,image=init_image, num_inference_steps=50, height=1024, width=1024).images[0]\n",
    "    else:\n",
    "      generated_image = pipe(prompt=prompt, num_inference_steps=50, height=1024, width=1024).images[0]\n",
    "\n",
    "\n",
    "    # Save the image to a bytes buffer\n",
    "    image_bytes = io.BytesIO()\n",
    "    generated_image.save(image_bytes, format='PNG')\n",
    "    image_bytes.seek(0)\n",
    "    # Save the byte stream to a file\n",
    "    file_path='genrated_image_text_2_img.png'\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(image_bytes.getvalue())\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2hQFgwRXLtW"
   },
   "source": [
    "# **Img to bytes**\n",
    "\n",
    "> Reads image using Pillow\n",
    "> Then Convert image array to bytes\n",
    "> Returns bytes object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "P85yNPm07ITF"
   },
   "outputs": [],
   "source": [
    "def image_file_to_bytes(file_path):\n",
    "    # Open the image file\n",
    "    with Image.open(file_path) as img:\n",
    "        # Save the image to a bytes buffer\n",
    "        image_bytes = io.BytesIO()\n",
    "        img.save(image_bytes, format='PNG')\n",
    "        image_bytes.seek(0)  # Move the cursor to the start of the buffer\n",
    "        return image_bytes#.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQpYyTuXPbG9"
   },
   "source": [
    "# ***ProfileGenz Bot***\n",
    "\n",
    "\n",
    "> Command usage /gen\n",
    "\n",
    "* User enter /gen >> Upload Source & Target Image  \n",
    "* Bot Process Img >> Send to Face detection\n",
    "* Faces BBOX (boundaries will be captured and return)\n",
    "* Sent to inswapper model for swapping >> return swapped image\n",
    "* Enhace img and upscale using codeformer RealESRGAN model\n",
    "* Generate Final Image and Return to user\n",
    "\n",
    "> Command usage /text2img\n",
    "* User enter text for image generation\n",
    "* bot send the prompt to image generation function\n",
    "* Using SDXL Image will be generated in 42 seconds on current setting of model\n",
    "* Image will be upscaled and sent to user\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMQbG_RjEzfV",
    "outputId": "5e9e2a8b-8eab-470f-af34-b61c3f72e168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document\n",
      "photo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inp: genrated_profile_image.png True True 2 0.5\n",
      "\timage size: (194, 259, 3)\n",
      "\tdetect 1 faces\n",
      "document\n",
      "photo\n",
      "Inp: genrated_profile_image.png True True 2 0.5\n",
      "\timage size: (320, 320, 3)\n",
      "\tdetect 1 faces\n",
      "document\n",
      "photo\n",
      "Inp: genrated_profile_image.png True True 2 0.5\n",
      "\timage size: (320, 320, 3)\n",
      "\tdetect 1 faces\n"
     ]
    }
   ],
   "source": [
    "import telebot\n",
    "from telebot import types, apihelper\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# First connecting our bot with telegram servers\n",
    "TOKEN = '7171360134:AAGaHXOrlrzv8r17BTImOybAMIi7dl_V2kM'\n",
    "\n",
    "# Create a telebot instance with custom request session\n",
    "bot = telebot.TeleBot(TOKEN)\n",
    "\n",
    "# Function to handle the /gen command\n",
    "@bot.message_handler(commands=['gen'])\n",
    "def start_generation(message):\n",
    "    bot.reply_to(message, 'Give your face image')\n",
    "    bot.register_next_step_handler(message, receive_face_image)\n",
    "\n",
    "# Function to handle receiving the face image\n",
    "def receive_face_image(message):\n",
    "    print(message.content_type)\n",
    "    if message.content_type == 'photo' or message.content_type==\"document\":\n",
    "        try:\n",
    "          file_info = bot.get_file(message.photo[-1].file_id)\n",
    "        except:\n",
    "          file_info = bot.get_file(message.document.file_id)\n",
    "        downloaded_file = bot.download_file(file_info.file_path)\n",
    "\n",
    "        # Save the image and open with Pillow\n",
    "\n",
    "        face_image = Image.open(io.BytesIO(downloaded_file))\n",
    "        face_image.save('face_image.png')\n",
    "\n",
    "        bot.reply_to(message, 'Face image received. Now send the target image.')\n",
    "        bot.register_next_step_handler(message, receive_target_image, face_image)\n",
    "    else:\n",
    "        bot.reply_to(message, 'Please send an image file.')\n",
    "        bot.register_next_step_handler(message, receive_face_image)\n",
    "\n",
    "# Function to handle receiving the target image\n",
    "def receive_target_image(message, face_image):\n",
    "    print(f'{message.content_type}')\n",
    "    if message.content_type == 'photo':\n",
    "        file_info = bot.get_file(message.photo[-1].file_id)\n",
    "        downloaded_file = bot.download_file(file_info.file_path)\n",
    "\n",
    "        # Save the image and open with Pillow\n",
    "        target_image = Image.open(io.BytesIO(downloaded_file))\n",
    "        bot.reply_to(message, 'Target image received.\\nPlease wait  while we proccess the image it may take few seconds.')\n",
    "\n",
    "        target_image.save('target_image.png')\n",
    "\n",
    "\n",
    "        bot.reply_to(message, 'Enhancing your images .')\n",
    "\n",
    "        # Add your image processing function here\n",
    "        result_image = image_generation(np.array(face_image), np.array(target_image))\n",
    "        # Convert the result back to a Pillow image\n",
    "        result_image = Image.fromarray(result_image)\n",
    "        result_image_bytes = io.BytesIO()\n",
    "        result_image.save(result_image_bytes, format='PNG')\n",
    "        #result_image_bytes.seek(0)\n",
    "        file_path='genrated_profile_image.png'\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(result_image_bytes.getvalue())\n",
    "        bot.reply_to(message, 'Profile generated successfully Now enhancing and upscaling.')\n",
    "        final_image=inference_app(\n",
    "  image=file_path,\n",
    "  background_enhance=True,\n",
    "  face_upsample=True,\n",
    "  upscale=2,\n",
    "  codeformer_fidelity=0.5,  file_name='generated_image'\n",
    "\n",
    ")\n",
    "        #final_image_bytes=image_file_to_bytes(final_image)\n",
    "        profile_image_bytes=image_file_to_bytes(final_image)\n",
    "        bot.send_photo(message.chat.id, profile_image_bytes, 'Here is the final image')\n",
    "    else:\n",
    "        bot.reply_to(message, 'Please send an image file.')\n",
    "        bot.register_next_step_handler(message, receive_target_image, face_image)\n",
    "# Function to handle the /genimage command\n",
    "@bot.message_handler(commands=['text2img'])\n",
    "def ask_for_prompt(message):\n",
    "    bot.reply_to(message, 'Please enter the text for image generation:')\n",
    "    bot.register_next_step_handler(message, receive_initial_image)\n",
    "\n",
    "def receive_initial_image(message):\n",
    "    print(message.content_type)\n",
    "    if message:  # .content_type == 'photo':\n",
    "        # Download the photo\n",
    "        if message.photo:\n",
    "            file_info = bot.get_file(message.photo[-1].file_id)\n",
    "            downloaded_file = bot.download_file(file_info.file_path)\n",
    "\n",
    "            # Ensure the downloaded file is not empty or corrupted\n",
    "            if not downloaded_file:\n",
    "                bot.reply_to(message, 'Failed to download the image. Please try again.')\n",
    "                return\n",
    "\n",
    "            try:\n",
    "                # Log the length of the downloaded file for debugging\n",
    "                print(f\"Downloaded file length: {len(downloaded_file)}\")\n",
    "\n",
    "                # Save the downloaded file to disk for further inspection\n",
    "                with open(\"downloaded_image.png\", \"wb\") as f:\n",
    "                    f.write(downloaded_file)\n",
    "\n",
    "                init_image = Image.open(\"downloaded_image.png\")\n",
    "                init_image = init_image.convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening image: {e}\")\n",
    "                bot.reply_to(message, 'Failed to process the image. Please send a valid image.')\n",
    "                return\n",
    "        else:\n",
    "            init_image = ''\n",
    "\n",
    "        # text_prompt = message.text  # 'change the background and make image realistic'  # Customize this as needed\n",
    "        text_prompt = message.caption if message.caption else message.text\n",
    "        print(f'Received caption: {text_prompt}')\n",
    "        bot.reply_to(message, f'Text and image received. Generating the image...')\n",
    "        print(f'Prompt for image generation: {text_prompt}')\n",
    "\n",
    "        # Generate image from prompt and initial image\n",
    "        generated_image = generate_image_from_prompt_and_image(text_prompt, init_image)\n",
    "        final_image=inference_app(\n",
    "  image=generated_image,\n",
    "  background_enhance=True,\n",
    "  face_upsample=True,\n",
    "  upscale=4,\n",
    "  codeformer_fidelity=0.5,  file_name='generated_image'\n",
    "\n",
    ")\n",
    "        final_image_bytes=image_file_to_bytes(final_image)\n",
    "        # Send the generated image to the user\n",
    "        bot.send_photo(message.chat.id, final_image_bytes, 'Here is the generated image')\n",
    "    else:\n",
    "        bot.reply_to(message, 'Please send a valid image.')\n",
    "        bot.register_next_step_handler(message, receive_initial_image)\n",
    "\n",
    "# Function to handle unrecognized commands\n",
    "@bot.message_handler(func=lambda m: True)\n",
    "def echo_all(message):\n",
    "    bot.reply_to(message, 'Command not recognized. Use /help to see all commands \\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bot.polling(none_stop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uARgSUfSyJj5"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A high-quality, professional LinkedIn profile picture of a businessman. The businessman is wearing a well-tailored dark business suit, a light-colored dress shirt, and a coordinating tie. He has a confident and friendly expression, with a neat haircut and a well-groomed appearance. The background is simple and blurred to ensure the focus remains on the subject. The lighting is even and flattering, highlighting the man's features and creating a polished and professional look. This image should convey professionalism, approachability, and competence, ideal for a LinkedIn profile.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0281b324a6274151ac31a5674d819dbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_3dc8ceb2df274f9b96eb6d300d847c3c",
      "placeholder": "​",
      "style": "IPY_MODEL_09e1e67aeeaa4b8398952cb3e8b65581",
      "value": ""
     }
    },
    "03af13bcd3e94bdd9446118abfce86c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07e4f197ebcd4822ab3e2a2b36655543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5eea486b51b34cb799eded87857ba3ad",
      "placeholder": "​",
      "style": "IPY_MODEL_4fb47c1b69894c12aa9a46345b07568a",
      "value": "Login successful"
     }
    },
    "09e1e67aeeaa4b8398952cb3e8b65581": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a20bd56ad7f479e95d0d3e721669883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0db0276e66c34700ae0a99bb1e0e2369": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ec0aafdfa4448e39c271a255e6b5fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc71a0e9b27c41168c56c2e75233ec2c",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7c2024b8f1747f1909b3b73469c5fb8",
      "value": 7
     }
    },
    "0f85ecca5d754781ad608963c64ef073": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16dca47caa2c43c5ac00549ee6c25268": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "190f0fb5bdba44c3b9608ae1614b26b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2531505b4b784db183365d99d526c361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2885c7585372420bb5aec8819ca7454c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcb70b2f526c46d68955c0bc1bb5127f",
      "placeholder": "​",
      "style": "IPY_MODEL_2531505b4b784db183365d99d526c361",
      "value": "Your token has been saved in your configured git credential helpers (store)."
     }
    },
    "28987dec357e4337a4f601b629dce447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c7f88fda52d4932bbbc606ce3f08527": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "364b8b9e53a041d8935bf465dfc5409d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "37dcee0369384427951611505f945117": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "3dc8ceb2df274f9b96eb6d300d847c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4902855b497e494eb5e4c01b7eaab4a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e2a60351fff40958844b1447694ea87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_2c7f88fda52d4932bbbc606ce3f08527",
      "style": "IPY_MODEL_0db0276e66c34700ae0a99bb1e0e2369",
      "value": true
     }
    },
    "4fb47c1b69894c12aa9a46345b07568a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5eea486b51b34cb799eded87857ba3ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "671071d5a6a349ceb71a7ce7b21bd8eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_190f0fb5bdba44c3b9608ae1614b26b5",
      "placeholder": "​",
      "style": "IPY_MODEL_16dca47caa2c43c5ac00549ee6c25268",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "678dcccf600f4de38909dc278a314f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_79f54caf4e5e4005bafebe2c948a24e1",
      "style": "IPY_MODEL_37dcee0369384427951611505f945117",
      "tooltip": ""
     }
    },
    "6e664d77697d426987f9dd9392196e7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76630b08d8af4785a1330298fae95bfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce9343a20c6740249ef5e347623c5337",
      "placeholder": "​",
      "style": "IPY_MODEL_28987dec357e4337a4f601b629dce447",
      "value": "Connecting..."
     }
    },
    "77b64e8b2be34a928e2dc5ba1f60f7cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5230212187640a8b185d9275d5cfd05",
       "IPY_MODEL_2885c7585372420bb5aec8819ca7454c",
       "IPY_MODEL_d57171b035674a0599c3e6f50afa8f13",
       "IPY_MODEL_07e4f197ebcd4822ab3e2a2b36655543"
      ],
      "layout": "IPY_MODEL_364b8b9e53a041d8935bf465dfc5409d"
     }
    },
    "79f54caf4e5e4005bafebe2c948a24e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d1656400bd54302b0867fb07fb93608": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b006b203843d4acd81b25a07fe68cdd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5b97db8c112456e94b7e5e6293fba72",
      "placeholder": "​",
      "style": "IPY_MODEL_4902855b497e494eb5e4c01b7eaab4a7",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "b0126a7860f84df1a6dadee64983496d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5b97db8c112456e94b7e5e6293fba72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7ae04a34f3b4ad5a8a590be6d78c031": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1c4f93d00ac4bde98b7c40b4d86498e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7ae04a34f3b4ad5a8a590be6d78c031",
      "placeholder": "​",
      "style": "IPY_MODEL_6e664d77697d426987f9dd9392196e7b",
      "value": "Loading pipeline components...: 100%"
     }
    },
    "c372370604e445a78462be8c7ecdbf69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c1c4f93d00ac4bde98b7c40b4d86498e",
       "IPY_MODEL_0ec0aafdfa4448e39c271a255e6b5fff",
       "IPY_MODEL_d827323911fe417ca0943bee5e644d48"
      ],
      "layout": "IPY_MODEL_8d1656400bd54302b0867fb07fb93608"
     }
    },
    "ce9343a20c6740249ef5e347623c5337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d18ccd7599eb45ad940cd2bc5295c227": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d57171b035674a0599c3e6f50afa8f13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f85ecca5d754781ad608963c64ef073",
      "placeholder": "​",
      "style": "IPY_MODEL_ef8fce68730e4bbe8d74405c1603ac20",
      "value": "Your token has been saved to /root/.cache/huggingface/token"
     }
    },
    "d827323911fe417ca0943bee5e644d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03af13bcd3e94bdd9446118abfce86c5",
      "placeholder": "​",
      "style": "IPY_MODEL_d18ccd7599eb45ad940cd2bc5295c227",
      "value": " 7/7 [00:02&lt;00:00,  2.70it/s]"
     }
    },
    "dc71a0e9b27c41168c56c2e75233ec2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef8fce68730e4bbe8d74405c1603ac20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f5230212187640a8b185d9275d5cfd05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0126a7860f84df1a6dadee64983496d",
      "placeholder": "​",
      "style": "IPY_MODEL_0a20bd56ad7f479e95d0d3e721669883",
      "value": "Token is valid (permission: fineGrained)."
     }
    },
    "f7c2024b8f1747f1909b3b73469c5fb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fcb70b2f526c46d68955c0bc1bb5127f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
